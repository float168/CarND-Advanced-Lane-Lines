{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project Demo\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "This demo show how the pipeline works, with test images firstly and then with project video.\n",
    "\n",
    "---\n",
    "## Calibrate camera using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pipeline\n",
    "\n",
    "\n",
    "debug = False\n",
    "\n",
    "importlib.reload(pipeline)\n",
    "chessboard_img_files = glob.glob(\"data/camera_cal/*.jpg\")\n",
    "chessboard_rgb_images = [pipeline.load_image(f) for f in chessboard_img_files]\n",
    "undistorter = pipeline.Undistorter(chessboard_rgb_images, (9,6))\n",
    "\n",
    "if debug:\n",
    "    print(\"camera matrix:\\n\", undistorter.camera_matrix)\n",
    "    print(\"distortion coefficients:\\n\", undistorter.distort_coeffs)\n",
    "    img = pipeline.load_image(\"data/camera_cal/calibration1.jpg\")\n",
    "    undistorted = undistorter.apply(img)\n",
    "    pipeline.save_image(\"output_images/undistorted_calibration1.jpg\", undistorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistort images using calibrated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image_files = glob.glob(\"data/test_images/*.jpg\")\n",
    "rgb_raw_images = [pipeline.load_image(f) for f in raw_image_files]\n",
    "rgb_undistorted_images = [undistorter.apply(rgb) for rgb in rgb_raw_images]\n",
    "\n",
    "if debug:\n",
    "    plt.imshow(rgb_undistorted_images[0])\n",
    "    pipeline.save_image(\"output_images/undistorted_test.jpg\", rgb_undistorted_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply threshold to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "extractor = pipeline.LaneFeatureExtractor(\n",
    "        ksize_dict={\n",
    "            'abs_sobel': 5,\n",
    "            'mag_sobel': 5,\n",
    "            'dir_sobel': 15,\n",
    "        },\n",
    "        thresh_dict={\n",
    "            'abs_sobel': (40,255),\n",
    "            'mag_sobel': (40,255),\n",
    "            'dir_sobel': (0.8,1.4),\n",
    "            'satur': (120, 255),\n",
    "        })\n",
    "\n",
    "binary_images = [extractor.extract(rgb, debug=debug) for rgb in rgb_undistorted_images]\n",
    "\n",
    "if debug:\n",
    "    pipeline.save_image(\"output_images/binary_test.jpg\", binary_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warp perspective into birdview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = binary_images[0].shape[0]\n",
    "warper = pipeline.Warper(\n",
    "        upper_left_point_pair=[\n",
    "            [526, 470], [300, 200]\n",
    "        ],\n",
    "        lower_left_point_pair=[\n",
    "            [0, height-1], [300, height-1]\n",
    "        ])\n",
    "\n",
    "warped_binary_images = [warper.forward_warp(img, debug=debug) for img in binary_images]\n",
    "\n",
    "if debug:\n",
    "    pipeline.save_image(\"output_images/warped_binary_test.jpg\", warped_binary_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane and embed lane info on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = pipeline.LaneDetector(\n",
    "        n_windows=9,\n",
    "        win_margin=60,\n",
    "        reposition_thresh_rate=(0.02, 0.8),\n",
    "        x_m_per_px=3.7/500,\n",
    "        y_m_per_px=25/700,\n",
    "        x_ignore_area=300,\n",
    "        )\n",
    "\n",
    "save_detected_test = True\n",
    "result_images = []\n",
    "for bin_img, raw_img in zip(warped_binary_images, rgb_undistorted_images):\n",
    "    detect_image_file = None\n",
    "    if debug and save_detected_test:\n",
    "        detect_image_file = \"output_images/detected_test.jpg\"\n",
    "    result_images.append(detector.draw_lane(bin_img, raw_img, warper, debug=debug, save_detection_to=detect_image_file))\n",
    "    if save_detected_test:\n",
    "        save_detected_test = False\n",
    "\n",
    "if debug:\n",
    "    pipeline.save_image(\"output_images/embeddted_test.jpg\", result_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to the project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct pipeline for stream processing\n",
    "# using undistorer, extractor, warper, detector\n",
    "def process_stream_image(raw_image):\n",
    "    undistorted = undistorter.apply(raw_image)\n",
    "    binary = extractor.extract(undistorted)\n",
    "    warped_binary = warper.forward_warp(binary)\n",
    "    embedded = detector.draw_lane(warped_binary, undistorted, warper, stream=True)\n",
    "    return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "input_video_file = \"data/videos/project_video.mp4\"\n",
    "output_video_file = \"output_videos/project_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 2/1260 [00:00<01:08, 18.47it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_videos/project_video.mp4.\n",
      "Moviepy - Writing video output_videos/project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  95%|█████████▍| 1193/1260 [02:00<00:06,  9.59it/s, now=None]"
     ]
    }
   ],
   "source": [
    "# Stream processing\n",
    "in_clip = VideoFileClip(input_video_file)\n",
    "out_clip = in_clip.fl_image(process_stream_image)\n",
    "%time out_clip.write_videofile(output_video_file, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"{width}\" height=\"{height}\" controls>\n",
    "  <source src=\"{file}\">\n",
    "</video>\n",
    "\"\"\".format(file=output_video_file, width=480, height=270))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   3%|▎         | 2/75 [00:00<00:04, 18.21it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video debug.mp4.\n",
      "Moviepy - Writing video debug.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready debug.mp4\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "head_clip = in_clip.subclip(0, 1)\n",
    "out_head_clip = head_clip.fl_image(process_stream_image)\n",
    "out_head_clip.write_videofile(\"debug.mp4\", audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.1.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
